{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Unspervised Learning**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**This notebook has been prepared by:**\n* Zizipho Tyeko\n* Siyamanga Malawu\n* Lejone Malokosta\n* Pfano Phungo\n* Mogau Mogashoa\n* Dunyiswa Matshaya","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### **How is the notebook gooinf to work?**\n\nThis notebook is a layout of a recommender system that is used to predict a movie user possible rating. The notebook will make use of the recommender system methods and techniques using sequential steps to get to the prediction of the possible expected results.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **Movie Recommendation Challenge**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **Recommender System**\n\nRecommender systems are amid the most well known applications of data science today. They are used to predict the \"rating\" or \"preference\" that a user would possibly give to an item. Recommender systems uses its techniques by searching through large volume of dynamically generated information to provide users with personalized content and services.\nTechnically recommender system has the ability to predict whether a particular user would prefer an item or not based on the user’s profile.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **Two types of Recommender System**\n\n* Content-Based Recommender System\n* Colaborative Filtering Recommender System","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Colaborative Filtering Recommender System\nColaborative filtering recommender systems are based on the past interactions recorded between users and items in order to produce new recommendations. These interactions are stored in the so-called “user-item interactions matrix”.\n\n### Advantages of Colaborative Filtering Recommender System\n* Works for any kind of item since no feature selection is needed\n* Requires not content analysis & extraction\n* Independent of any machine-readable representation of the objects being recommended\n* More diverse and serendipitous recommendation \n\n### Disadvantage of Colaborative Filtering Recommender System\n* Cold Start problem\n* Popularity bias\n* Spacity: Hard to find users that have rated the same item","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **Content-Based Recommender System**\ncontent based recommender sytem  use additional information about users and/or items to predict.This additional information can be, for example, the age, the sex, the job or any other personal information for users.\n\n### Advantages of Content-Based Recommender Sytem\n* Content representations are varied and they open up the options to use different approaches like: text processing techniques, the use of semantic information, inferences, etc…\n* It is easy to make a more transparent system: we use the same content to explain the recommendations.\n* We can avoid the “new item problem”\n\n### Disadvantages of Content-Based Recommender Sytem\n* Content-Based RecSys tend to over-specialization: they will recommend items similar to those already consumed, with a tendecy of creating a “filter bubble”.\n* The methods based on Collaborative Filtering have shown to be, empirically, more precise when generating recommendations\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **Introduction**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The aim of this notebook is to predict how a user will rate a movie they have not yet viewed, based on their historical preference on a movie website or application e.g Netflix, Showmax or Amazon Prime.\n\nMovie websites and applications can improve their reliability and enhance their customer experience by providing an estimated rating or preference of a movie through a recommender system used to model the predicted results.\n\nRecommender systems are essential economically and socially in today's technology driven world. This can help movie companies in ensuring that their users can make the appropriate choices surrounding the content that they regulary engage with.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **Problem Statement**\nCan we construct a recommendation algorithm based on content or collaborative filtering, capable of accurately predicting how a user will rate a movie they have not yet viewed based on their historical preferences.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **Aim**\nDesign a recommendersystem which will predict a user possible rating on a movie that they have not viewed yet based on they user history of their movie ratings.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **Scope**\nThe scope of this project is to analyse and search through large volume of dynamically generated information consisting of movie ratings given by a user and information describing the movie.\nThese ratings will be used to train machine learning models to help with the prediction of the ratings given by a user on an unseen movie. This could also help with providing users with personalised content and services.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://posteet.com/wp-content/uploads/2019/11/movies.png\" width=90%>","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# **Table of Content**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"1. Import packages\n2. Loading Datasets\n3. Data Description\n4. Explanotory Data Analysis\n5. Data Filtering\n6. Varibale Selection\n7. Modeling\n8. Model Comparison\n9. Model Explanation\n10. Submission\n11. Application Pickled files\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install scikit-surprise","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install surprise","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Importing packages","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# utilities\nimport numpy as np\nimport pandas as pd\n\n#pre-processing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n#plotting\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nimport seaborn as sns\nimport cufflinks as cf\nplt.style.use('ggplot')\n%matplotlib inline\nsns.set()\n\nfrom sklearn.metrics import mean_squared_error\nfrom scipy import stats\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel, cosine_similarity\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk.corpus import wordnet\nfrom surprise import Reader, Dataset, SVD\nfrom surprise.model_selection import cross_validate\n\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Loading Datasets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/edsa-recommender-system-predict/train.csv') \ntest = pd.read_csv('../input/edsa-recommender-system-predict/test.csv')\nscores = pd.read_csv('../input/edsa-recommender-system-predict/genome_scores.csv')\ntags = pd.read_csv('../input/edsa-recommender-system-predict/genome_tags.csv')\nimbd = pd.read_csv('../input/edsa-recommender-system-predict/imdb_data.csv') \nlinks = pd.read_csv('../input/edsa-recommender-system-predict/links.csv') \nmovies = pd.read_csv('../input/edsa-recommender-system-predict/movies.csv')\nsample = pd.read_csv('../input/edsa-recommender-system-predict/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Data Description","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['rating'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tags.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imbd.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imbd_df = imbd.copy()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"imbd_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#budget1 = imbd_df.budget\n\nimbd_df['budget'].replace(regex=True, inplace=True, to_replace=r'[^0-9.\\-]',value=r'') \nimbd_df['budget'] = imbd_df['budget'].astype(float)\n\n#re.sub(r'[a-z]+', '', budget, re.I)\n\n\n#imbd_df1 = re.sub(\"[^0-9]\", \"\", budget)\n\n#print(imbd_df1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imbd_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imbd_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"links.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies.head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies_df = movies.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmovies_df['Year'] = movies_df['title'].str.extract(r'(?!\\()\\b(\\d+){1}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Pre-processing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create short list of unwanted columns\nlabels = ['timestamp']\n\n# declare the features to be all columns, less the unwanted ones from above\nfeatures = [col for col in train.columns if col not in labels]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#I did not run this by zizipho\ncf.set_config_file(offline=True, world_readable=True, theme='ggplot')\n\n# using plotly to plot the boxplot\ntrain[features].iplot(kind='box', title=\"Boxplots of Features (Unscaled)\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Removing duplicates ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dup_bool = train.duplicated(['movieId','userId','rating'])\ndups = sum(dup_bool) # by considering all columns..( including timestamp)\nprint(\"There are {} duplicate rating entries in the data..\".format(dups))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  4. **Exploratory Data Analysis**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()['rating']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Boxplot**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"box = train['rating']\nplt.boxplot(box)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Total Number of ratings, users and movies**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total data \")\nprint(\"-\"*50)\nprint(\"\\nTotal no of ratings :\",train.shape[0])\nprint(\"Total No of Users   :\", len(np.unique(train.userId)))\nprint(\"Total No of movies  :\", len(np.unique(train.movieId)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# method to make y-axis more readable\ndef human(num, units = 'M'):\n    units = units.lower()\n    num = float(num)\n    if units == 'k':\n        return str(num/10**3) + \" K\"\n    elif units == 'm':\n        return str(num/10**6) + \" M\"\n    elif units == 'b':\n        return str(num/10**9) +  \" B\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nplt.title('Distribution of ratings over Training dataset', fontsize=15)\nsns.countplot(train.rating)\nax.set_yticklabels([human(item, 'M') for item in ax.get_yticks()])\nax.set_ylabel('No. of Ratings(Millions)')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#number of rated movies per user\nno_of_rated_movies_per_user = train.groupby(by='userId')['rating'].count().sort_values(ascending=False)\n\nno_of_rated_movies_per_user.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"no_of_rated_movies_per_user.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"no_of_ratings_per_movie = train.groupby(by='movieId')['rating'].count().sort_values(ascending=False)\n\nfig = plt.figure(figsize=plt.figaspect(.5))\nax = plt.gca()\nplt.plot(no_of_ratings_per_movie.values)\nplt.title('# RATINGS per Movie')\nplt.xlabel('MovieId')\nplt.ylabel('No of Users who rated a movie')\nax.set_xticklabels([])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_data = pd.merge(train, movies, on='movieId')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_data.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sort mean movie rating by title in ascending order\nmovie_data.groupby('title')['rating'].mean().sort_values(ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#group movies by the number of ratings in ascending orde\nmovie_data.groupby('title')['rating'].count().sort_values(ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#mean count of ratings\nratings_mean_count = pd.DataFrame(movie_data.groupby('title')['rating'].mean())\nratings_mean_count['rating_counts'] = pd.DataFrame(movie_data.groupby('title')['rating'].count())\nratings_mean_count.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can see movie title, along with the average rating and number of ratings for the movie.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"A histogram for the number of ratings represented by the \"rating_counts\" column in the above dataframe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('dark')\n%matplotlib inline\n\nplt.figure(figsize=(8,6))\nplt.rcParams['patch.force_edgecolor'] = True\nratings_mean_count['rating_counts'].hist(bins=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the output, you can see that most of the movies have received less than 50 ratings. While the number of movies having more than 5000 ratings is very low.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"A histogram for average ratings","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.rcParams['patch.force_edgecolor'] = True\nratings_mean_count['rating'].hist(bins=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can see that the integer values have taller bars than the floating values since most of the users assign rating as integer value i.e. 1, 2, 3, 4 or 5. Furthermore, it is evident that the data has a weak normal distribution with the mean of around 3.5. There are a few outliers in the data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Average ratings against the number of ratings:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.rcParams['patch.force_edgecolor'] = True\nsns.jointplot(x='rating', y='rating_counts', data=ratings_mean_count, alpha=0.4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Budget of movies**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":" budget = pd.merge(imbd, movies, on='movieId')\nbudget.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#top 5 movies with longest running time\nbudget['runtime'] = budget['runtime'].astype(float)\nb = budget.drop(['movieId','title_cast', 'director', 'budget', 'plot_keywords', 'genres'], axis=1)\nb.head()\nb.nlargest(5,['runtime'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The longest movie is Taken (2002)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## fitting model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Independent feature of the train dataframe\nX = train.drop(['rating'], axis=1)\n#Dependent feature of the train dataframe\ny=train['rating']\n#Independent feature of test dataframe\nx_unseen=test['movieId'] #test independent feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting the train dataset\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectoriser = TfidfVectorizer(stop_words='english', \n                             min_df=1, \n                             max_df=0.9, \n                             ngram_range=(1, 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fitting the vectoriser\nvectoriser.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transformation of the datasets\nX_train = vectoriser.transform(X)\nX_test  = vectoriser.transform(X)\n#x_unseen =  vectoriser.transform(x_unseen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params={\n \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30] ,\n \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15,20,30,40],\n \"min_child_weight\" : [ 1, 3, 5, 7 ,9,10,11,12],\n \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4,1,2],\n \"colsample_bytree\" : [ 0.2,0.3, 0.4, 0.5 , 0.7,0.8 ]\n \n    \n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Hyperparameter optimization using RandomizedSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nimport xgboost as xgb\nboost = xgb.XGBRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search=RandomizedSearchCV(boost,param_distributions=params,n_iter=2,n_jobs=1,cv=2,verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# initialize Our first XGBoost model...\nboost = xgb.XGBRegressor()\nboost.fit(X,y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting predicions from the X_test\npred0 = boost.predict(X_test)\n#checking score\nmean_squared_error(y_test, pred0, squared=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}